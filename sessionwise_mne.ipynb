{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd5e172",
   "metadata": {},
   "source": [
    "#### Code for  adapted from https://github.com/lokinou/p3k_offline_analysis\n",
    "\n",
    "commit e273e9e42380d6c117feec1ef7ca00851b09092e (06.08.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36662544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the line wit qt below to obtain separate plots to save\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "#matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ddd95",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Adaptaions:\n",
    "- microvolt/volt scaling in function\n",
    "- channel names are adjusted for the sessions with changed postions \n",
    "    since they were still plugged in the same positions to the pre-Amp they need to be called by the wrong names when looking for the EEG signal in the loadBCI2k function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import mne\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "# LDA\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4811de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import mne\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "# LDA\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from BCI2kReader import BCI2kReader as b2k\n",
    "from BCI2kReader import FileReader as f2k\n",
    "\n",
    "raws = []\n",
    "\n",
    "def extract_annotations(filename, verbose=False):\n",
    "    display_preprocessing_plots = False\n",
    "    file= b2k.BCI2kReader(filename)\n",
    "\n",
    "    if verbose:\n",
    "        print(file.states)\n",
    "    target_states = np.squeeze(file.states['StimulusType'])\n",
    "    stimulus_codes = np.squeeze(file.states['StimulusCode'])\n",
    "    if 'StimulusBegin' in file.states.keys():\n",
    "        stimulus_begin = np.squeeze(file.states['StimulusBegin'])\n",
    "    else:\n",
    "        stimulus_begin = np.squeeze(file.states['Flashing'])\n",
    "    \n",
    "    phase = np.squeeze(file.states['PhaseInSequence'])\n",
    "\n",
    "    fs = file.samplingrate\n",
    "\n",
    "    idx_targets = np.where(target_states)[0]\n",
    "    idx_codes = np.where(stimulus_codes>0)[0]\n",
    "    idx_begin = np.where(stimulus_begin>0)[0]\n",
    "\n",
    "\n",
    "    # In BCI2000 states are maintained over different samples, we search here the differences of when the codes are > 0\n",
    "    groups = np.split(idx_codes, np.where(np.diff(idx_codes) != 1)[0]+1)\n",
    "    # we take the first sample where a difference can be found\n",
    "    code_change_idx = np.array([g[0] for g in groups])\n",
    "    #[idx_codes[idx] for idx in code_change_idx]\n",
    "    print('nb stimuli={}'.format(len(code_change_idx)))\n",
    "\n",
    "    # we intersect the target index list with the code change to find the onset of targets and non-targets\n",
    "    target_idx=np.intersect1d(code_change_idx,idx_targets)\n",
    "    print('nb targets={}'.format(len(target_idx)))\n",
    "    non_target_idx= np.setdiff1d(code_change_idx,idx_targets)\n",
    "\n",
    "    # Translating into MNE Annotations \n",
    "    # define the annotations from the recovered stimuli (in seconds)\n",
    "    sample_lengh = 1/fs\n",
    "    onsets = code_change_idx * sample_lengh\n",
    "    onsets = np.repeat(onsets, 2)  # repeat onsets\n",
    "    # define the descriptio\n",
    "    description_targets = np.zeros(code_change_idx.shape, dtype=np.uint)\n",
    "    # index of targets in the list of stimuli onsets\n",
    "    description_targets[np.searchsorted(code_change_idx, target_idx)] = 1\n",
    "    description_codes = stimulus_codes[code_change_idx] + stimulus_padding  # start codes at 100 because 0 and 1 are used for target and nontarget\n",
    "    # merge code and target decriptions\n",
    "    description = np.zeros(description_targets.shape[0]*2, dtype=np.uint)\n",
    "    description[np.arange(description_targets.shape[0]*2, step=2)] = description_codes\n",
    "    description[np.arange(start=1, stop=(description_targets.shape[0]*2)+1, step=2)] = description_targets\n",
    "\n",
    "    if display_preprocessing_plots:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(description[:100])\n",
    "        fig.suptitle('Targets(1) and non-targets(0) for 100 first stimuli')\n",
    "\n",
    "    if display_preprocessing_plots:\n",
    "        fig = plt.figure()\n",
    "        plt.plot(phase == 1)\n",
    "        fig.suptitle('Trial begin')\n",
    "\n",
    "    # extract trial begin markers  #  this method does not work since some stimuli are declared before phase==1\n",
    "    # let's think baclwards use the end markers instead\n",
    "    new_phase_continuous = np.where(phase == 1)[0]\n",
    "    groups = np.split(new_phase_continuous, np.where(np.diff(new_phase_continuous) != 1)[0]+1)\n",
    "    new_trial_idx = np.array([g[0] for g in groups]) if len(groups) > 1 else None\n",
    "    \n",
    "    \n",
    "    # extract trial end markers\n",
    "    new_phase_continuous = np.where(phase == 3)[0]\n",
    "    groups = np.split(new_phase_continuous, np.where(np.diff(new_phase_continuous) != 1)[0]+1)\n",
    "    end_of_trial_idx = np.array([g[-1] for g in groups]) # take the last index to integrate all post sequence duration\n",
    "    \n",
    "    # deduce trial begin markers  # \n",
    "    #new_trial_idx = np.zeros(end_of_trial_idx.size)\n",
    "    #new_trial_idx[1:] = end_of_trial_idx[1:]+1\n",
    "\n",
    "    print(new_trial_idx)\n",
    "    print(end_of_trial_idx)\n",
    "    \n",
    "    \n",
    "    if new_trial_idx is None:\n",
    "        print('WARNING: markers for begin trial (PhaseInSequence=1) missing (in old brain painting dev versions)!!!, using end of trial instead')\n",
    "        new_trial_idx = [0]\n",
    "        new_trial_idx.extend(end_of_trial_idx[0:-1])  # deduce the bounds from end of trial\n",
    "        new_trial_idx = np.array(new_trial_idx)  # convert to numpy\n",
    "        print(new_trial_idx)\n",
    "    \n",
    "    if new_trial_idx.shape[0] > end_of_trial_idx.shape[0]:\n",
    "        print('WARNING: no end of trial for the last trial (interrupted recording?), it will be ignored for offline accuracy calculation')\n",
    "        inter_trial_duration = end_of_trial_idx[0:len(new_trial_idx)] - new_trial_idx\n",
    "    else:\n",
    "        inter_trial_duration = end_of_trial_idx - new_trial_idx\n",
    "        \n",
    "    inter_trial_duration = inter_trial_duration * sample_lengh  # express in seconds\n",
    "\n",
    "\n",
    "    print(\"Extracted {} trials\".format(len(new_trial_idx)))\n",
    "\n",
    "    # set a non-zero duration for stimuli (or MNE ignores them)\n",
    "    duration = np.ones(onsets.shape) * sample_lengh\n",
    "\n",
    "\n",
    "    # merge phase in sequence events with stimuli onsets\n",
    "    onsets_phase = new_trial_idx * sample_lengh\n",
    "    onsets = np.concatenate((onsets, onsets_phase))\n",
    "    \n",
    "    duration = np.concatenate((duration, inter_trial_duration))\n",
    "    description = np.concatenate((description, np.ones(new_trial_idx.shape) * 10))  # concatenate trials markers=10\n",
    "    srt = np.argsort(onsets) # sort according to their timing\n",
    "    onsets=onsets[srt]\n",
    "    duration = duration[srt]\n",
    "    description = description[srt].astype(np.uint8)\n",
    "    inter_trial_duration\n",
    "    annotations = mne.Annotations(onset=onsets, duration=duration, description=description)\n",
    "\n",
    "    file.flush()\n",
    "    return annotations\n",
    "\n",
    "def load_bci2k(filename_list, verbose=False):\n",
    "    \"\"\"\n",
    "    return MNE raw, number of rows in the matrix\n",
    "    \"\"\"\n",
    "    raws = []\n",
    "    for fn in filename_list:\n",
    "        cname = None\n",
    "        with b2k.BCI2kReader(fn) as file:\n",
    "            \n",
    "            # Extract signals and states\n",
    "            print('Reading {}'.format(fn))\n",
    "            eeg_data = file.signals\n",
    "            states = file.states\n",
    "            fs = file.samplingrate\n",
    "            nb_chan = eeg_data.shape[0]\n",
    "            #file.purge()\n",
    "\n",
    "            # Extract channel names\n",
    "            reader = f2k.bcistream(fn)\n",
    "            if verbose:\n",
    "                print(reader.params)\n",
    "            # actualize the parameters by including the defined channel names\n",
    "            if len(reader.params['ChannelNames']):\n",
    "                if cname != reader.params['ChannelNames']:\n",
    "                    cname = reader.params['ChannelNames']\n",
    "                    print('Actualized channel names to {}'.format(cname))\n",
    "\n",
    "            if cname is None:\n",
    "                cname = [str(ch_n) for ch_n in list(range(nb_chan))]\n",
    "                \n",
    "            # extract the number of rows\n",
    "            nb_stim_rows = np.uint8(reader.params['NumMatrixRows'][0])\n",
    "            nb_stim_cols = np.uint8(reader.params['NumMatrixColumns'][0])\n",
    "            nb_seq = np.uint8(reader.params['NumberOfSequences'])\n",
    "\n",
    "            # convert states into annotations\n",
    "            info = mne.create_info(cname, fs, ch_types='eeg', verbose=None)\n",
    "            raw_array = mne.io.RawArray(eeg_data, info)\n",
    "            # Manually force the filename or mne complains\n",
    "            raw_array._filenames = [os.path.basename(fn)]\n",
    "            \n",
    "            # If the variance of the data is >1, it means the data is expressed in microvolts\n",
    "            # Since MNE uses Volt as a default value, we rescale microvolts to volt\n",
    "            if np.var(raw_array._data)>1:\n",
    "                raw_array._data = raw_array._data * 1.e-6\n",
    "                print('Rescaled signal to Volt (mean variance={})'.format(np.var(raw_array._data)))\n",
    "            \n",
    "            annotations = extract_annotations(fn, verbose= False)\n",
    "            raw_array.set_annotations(annotations)\n",
    "            raws.append(raw_array)\n",
    "    return raws, (nb_stim_rows, nb_stim_cols, nb_seq)\n",
    "\n",
    "#fn = [\"./data_sample/bci2000\\Heide_einsteinBP_calibration4S001R01.dat\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c565b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a60107",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stimulus_padding  = 100\n",
    "old_cnames = [\"Fz\",\"Fc1\",\"Fc2\",\"C3\",\"Cz\",\"C4\",\"P3\",\"Pz\",\"P4\",\"O1\",\"Oz\",\"O2\"]\n",
    "new_cnames = [\"Fz\",\"Fc1\",\"Fc2\",\"C3\",\"C1\",\"Cz\",\"C2\",\"C4\",\"Cp1\",\"Cpz\",\"Cp2\",\"Pz\"] # changed on 12.12.20 (sess021)\n",
    "CNAMES = dict(zip(old_cnames,new_cnames))\n",
    "os.chdir(r\"D:\\Master\\Masterarbeit\\Data\\dat_files\\all_files\")\n",
    "session_list = list(range(21,50)) #.append(\"all\")\n",
    "pickle_path = \"D:\\Master\\Masterarbeit\\Data\\mne_raw_pickle\" \n",
    "for sess in range(1,50):\n",
    "    for mode in [\"Calib\",\"Free\"]:\n",
    "        fnames = [i for i in glob.glob(\"tac\"+mode+\"S*\"+f\"{sess:03}\"+\"R*.dat\")] #tac___S___R____.dat\n",
    "        if len(fnames)!=3: # check if all trials are there, if not exclude session\n",
    "            print(\"ATTENTION__________________________________ Something wrong with session {}\".format(sess))\n",
    "            continue\n",
    "        signal_with_matrix_params = load_bci2k(fnames,verbose=False)\n",
    "        if sess >= 21:\n",
    "            for raw_signal in signal_with_matrix_params[0][:]:\n",
    "                mne.rename_channels(raw_signal.info,CNAMES,verbose=True)\n",
    "                print('ATTENTION__________________________________Updated channel names to {}'.format(new_cnames))\n",
    "        #print(\"Using from parameters n_rows={}, n_cols={}, n_seq={}\".format(nb_stimlus_rows, nb_stimulus_cols, nb_seq))\n",
    "        extension = mode+\"_S\"+str(sess).zfill(3)+\"_TEST.pickle\"\n",
    "        with open(os.path.join(pickle_path,extension), \"wb\") as file:\n",
    "            pickle.dump(signal_with_matrix_params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889615e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signal_with_matrix_params[0][2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341138be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
