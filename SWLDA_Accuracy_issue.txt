closest to BCI 2000

#best approach at the moment_
calculate probability to belong to target class of each feature, sum the proabilities and evaluate

channel set 1:12
-> classifer weights seem simmilar, gleiche channels, gewicht minimale abweichungen <0.2?
-> nope! same channels still true for other sessions, more features included in the BCI2000
-> Py3GUI also uses some kind of spatial filter: NO, seems to be just a diagonal matrix ==1 


Accuracy Calculation still differs from BCI2000 even if same classifier is loaded

-> implementation in own script:
	calculate feature weights with script from Py3GUI
	extract features from data and
		 load into an LDA? -> should reduce dimensionality again by 1
		 take sum of the features, classify > 0 as target? ---> nope
			there should be an offset/ constant - where the hell is the constant???
	- tried whitening and calculating the MDM (euclidean) - LDA is usuallay Malanhobis (but not when whitened)?
		after applying feature weights worse than just extracting the features - are feature weights scaling the data already?


->Py3GUI resamples to extract the features (20Hz), for classification the resampling is "revesed", (single feature (channel/timepoint) extended to channel/several timepoints covered by the resampled one)


 -> even if I load .prm from BCI2000 Py3GUI calculates a different accuracy
--> float/ integer issues python2
	solved by from __future__ import division
--> WARNING "VisualizeSourceBufferSize"// "PreSequenceDuration"
	did not change anything in classification



Resampling:
Py3GUI creates one sample less (410 samples, decimated by 26, 290 (15) last fit)
- compare resampling during calculation of swlda-featureweights to resampling during response collection (my script)
    of course it's different - use mne resampled data to create feature matrix - currently not creating a matrix, but an array - this shouldn't make a difference
- tried different timings 0,800 0,850 or 0,900
    -> 850 has lowest deviation from BCI2000
    -> 900 has highest accuracy
    -> 800 thats how we always did it and I dont like change

TODO:
Classifier Matrizen BCI2000
    super weirder kram: manchmal veränderte Anzahl an Samples, manchmal Channel...
    Channels: nie 12 channel gebraucht, trotzdem meistens 12 channels, manchmal aber auch nicht
    Samples: Vermutung wenn die letzten samples = 0 dann raus - auch nicht wahr...
    manchmal sind die Gewichte deckungsgleich, manchmal passen sie überhaupt nicht...

Feature weights scheinen identisch zu sein, sofern nicht geresampelt wird

vgl resampling mit mne und resampling via py3gui
-> matrizen annähernd gleich, shape/gewichte nicht identisch, außreißer liegen an den selben stellen (eg. sess1 sample 120: letzten werte extrem hoch)

-Fragen:
Pipeline - Mitteln der Epochen
    bevor die feature matrix gebildet wird?
    bevor die Daten klassifierziert werden?

    momentan (stand Masterarbeit: mitteln der Epochen erst nach der berechnung der Wahrscheinlichkeiten)